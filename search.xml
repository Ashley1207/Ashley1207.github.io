<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>First Blog</title>
    <url>/2020/04/27/zyqfirstBlog/</url>
    <content><![CDATA[<p>首次使用hexo出现的错误—-报空格错误<br><img src="/2020/04/27/zyqfirstBlog/2020-05-02-15-30-33.png" alt><br>原因是自己最上面加了注释，才导致博客一直发布不了，搞的自己差点放弃,好在结局是好的，搞了两天总算是把自己的博客给搭建好了，很开心，还专门买了一个域名玩玩。</p>
<p>本次搭建hexo博客主要是参考<a href="https://www.jianshu.com/p/77db3862595c" target="_blank" rel="noopener">https://www.jianshu.com/p/77db3862595c</a>，修改了主题，加入了访问量，但是评论还没加，等有时间再搞吧。</p>
<p>购买了阿里的域名，9块钱一年的，还挺便宜，域名的设置是参考<a href="https://www.jianshu.com/p/1dc893a05234" target="_blank" rel="noopener">https://www.jianshu.com/p/1dc893a05234</a>以及<a href="https://blog.csdn.net/mqdxiaoxiao/article/details/92799543" target="_blank" rel="noopener">https://blog.csdn.net/mqdxiaoxiao/article/details/92799543</a><br>唯一的缺点就是访问有点慢<br>另外编写markdown使用的是vscode，paste Image真是一个超好用的插件，我用quiver写markdown时图片可以直接复制粘贴，这个插件也实现了这个功能</p>
<p>好吧，后来又出现了一个图片显示不出来的bug，下载<a href="https://github.com/CodeFalling/hexo-asset-image" target="_blank" rel="noopener">https://github.com/CodeFalling/hexo-asset-image</a>,<br>然后将配置里面的<strong>post_asset_folder: true</strong>改成这样就可以了</p>
<p>我就奇了怪了，我自己手动建立的文件夹不能部署到github上，因为我想把图片单纯的存在一个文件夹里，但这样就不行</p>
]]></content>
      <tags>
        <tag>hexo-bug</tag>
      </tags>
  </entry>
  <entry>
    <title>青春有你可视化</title>
    <url>/2020/05/03/%E9%9D%92%E6%98%A5%E6%9C%89%E4%BD%A0%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
    <content><![CDATA[<p><strong>对爬取的青春有你2参赛选手的信息进行数据可视化</strong></p>
<h1 id="一-绘制选手区域分布柱状图"><a href="#一-绘制选手区域分布柱状图" class="headerlink" title="一. 绘制选手区域分布柱状图"></a>一. 绘制选手区域分布柱状图</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt</span><br><span class="line"><span class="keyword">import</span> numpy as np </span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> matplotlib.font_manager as font_manager</span><br><span class="line"></span><br><span class="line">#显示matplotlib生成的图形</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="function">with <span class="title">open</span><span class="params">(<span class="string">'data/data31557/20200422.json'</span>, <span class="string">'r'</span>, encoding=<span class="string">'UTF-8'</span>)</span> as file:</span></span><br><span class="line"><span class="function">         json_array </span>= json.loads(file.read())</span><br><span class="line"></span><br><span class="line">#绘制小姐姐区域分布柱状图,x轴为地区，y轴为该区域的小姐姐数量</span><br><span class="line"></span><br><span class="line">zones = []</span><br><span class="line"><span class="keyword">for</span> star in json_array:</span><br><span class="line">    zone = star[<span class="string">'zone'</span>]</span><br><span class="line">    zones.append(zone)</span><br><span class="line">print(len(zones))</span><br><span class="line">print(zones)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">zone_list = []</span><br><span class="line">count_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> zone in zones:</span><br><span class="line">    <span class="keyword">if</span> zone not in zone_list:</span><br><span class="line">        count = zones.count(zone)</span><br><span class="line">        zone_list.append(zone)</span><br><span class="line">        count_list.append(count)</span><br><span class="line"></span><br><span class="line">print(zone_list)</span><br><span class="line">print(count_list)</span><br><span class="line"></span><br><span class="line"># 设置显示中文</span><br><span class="line">plt.rcParams['font.sans-serif'] = ['SimHei'] # 指定默认字体</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line">plt.bar(range(len(count_list)), count_list,color=<span class="string">'r'</span>,tick_label=zone_list,facecolor=<span class="string">'#9999ff'</span>,edgecolor=<span class="string">'white'</span>)</span><br><span class="line"></span><br><span class="line"># 这里是调节横坐标的倾斜度，rotation是度数，以及设置刻度字体大小</span><br><span class="line">plt.xticks(rotation=<span class="number">45</span>,fontsize=<span class="number">20</span>)</span><br><span class="line">plt.yticks(fontsize=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">''</span><span class="string">'《青春有你2》参赛选手'</span><span class="string">''</span>,fontsize = <span class="number">24</span>)</span><br><span class="line">plt.savefig(<span class="string">'/home/aistudio/work/result/bar_result.jpg'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt</span><br><span class="line"><span class="keyword">import</span> numpy as np </span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> matplotlib.font_manager as font_manager</span><br><span class="line"><span class="keyword">import</span> pandas as pd</span><br><span class="line"></span><br><span class="line">#显示matplotlib生成的图形</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df = pd.read_json(<span class="string">'data/data31557/20200422.json'</span>)</span><br><span class="line">#print(df)</span><br><span class="line"></span><br><span class="line">grouped=df[<span class="string">'name'</span>].groupby(df[<span class="string">'zone'</span>])</span><br><span class="line">s = grouped.count()</span><br><span class="line"></span><br><span class="line">zone_list = s.index</span><br><span class="line">count_list = s.values</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 设置显示中文</span><br><span class="line">plt.rcParams['font.sans-serif'] = ['SimHei'] # 指定默认字体</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line">plt.bar(range(len(count_list)), count_list,color=<span class="string">'r'</span>,tick_label=zone_list,facecolor=<span class="string">'#9999ff'</span>,edgecolor=<span class="string">'white'</span>)</span><br><span class="line"></span><br><span class="line"># 这里是调节横坐标的倾斜度，rotation是度数，以及设置刻度字体大小</span><br><span class="line">plt.xticks(rotation=<span class="number">45</span>,fontsize=<span class="number">20</span>)</span><br><span class="line">plt.yticks(fontsize=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">''</span><span class="string">'《青春有你2》参赛选手'</span><span class="string">''</span>,fontsize = <span class="number">24</span>)</span><br><span class="line">plt.savefig(<span class="string">'/home/aistudio/work/result/bar_result02.jpg'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h1 id="二-绘制饼状图"><a href="#二-绘制饼状图" class="headerlink" title="二. 绘制饼状图"></a>二. 绘制饼状图</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt</span><br><span class="line"><span class="keyword">import</span> numpy as np </span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> matplotlib.font_manager as font_manager</span><br><span class="line"></span><br><span class="line">#显示matplotlib生成的图形</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">df = pd.read_json(<span class="string">'data/data31557/20200422.json'</span>)</span><br><span class="line"></span><br><span class="line">weights = df[<span class="string">'weight'</span>]</span><br><span class="line">arrs = weights.values</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">for</span> i in <span class="title">range</span><span class="params">(len(arrs)</span>):</span></span><br><span class="line"><span class="function">    arrs[i] </span>= <span class="keyword">float</span>(arrs[i] [<span class="number">0</span>:-<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">bin = [<span class="number">0</span>,<span class="number">45</span>,<span class="number">50</span>,<span class="number">55</span>,<span class="number">100</span>]</span><br><span class="line">sel = pd.cut(arrs,bin)</span><br><span class="line"></span><br><span class="line">#pandas的value_counts()函数可以对series里面的每个值进行计数并且排序</span><br><span class="line">pd.value_counts(sel)</span><br><span class="line"></span><br><span class="line">labels = <span class="string">'&lt;= 45kg'</span>,<span class="string">'45~50kg'</span>,<span class="string">'50~55kg'</span>,<span class="string">'&gt;55kg'</span></span><br><span class="line">sizes = pd.value_counts(sel)</span><br><span class="line">explode = (<span class="number">0.1</span>,<span class="number">0.1</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">fig1,ax1 = plt.subplots()</span><br><span class="line">ax1.pie(sizes,explode = explode, labels = labels, autopct = <span class="string">'%1.1f%%'</span>,shadow = True,startangle = <span class="number">90</span>)</span><br><span class="line">ax1.axis(<span class="string">'equal'</span>)</span><br><span class="line">plt.legend(loc = <span class="string">"best"</span>)</span><br><span class="line">plt.title(<span class="string">''</span><span class="string">'《青春有你2》参赛选手'</span><span class="string">''</span>,fontsize = <span class="number">24</span>)</span><br><span class="line">plt.savefig(<span class="string">'/home/aistudio/work/result/pie_result.jpg'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt</span><br><span class="line"><span class="keyword">import</span> numpy as np </span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> matplotlib.font_manager as font_manager</span><br><span class="line"></span><br><span class="line">#显示matplotlib生成的图形</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">df = pd.read_json(<span class="string">'data/data31557/20200422.json'</span>)</span><br><span class="line"></span><br><span class="line">weights = df[<span class="string">'weight'</span>]</span><br><span class="line">arrs = weights.values</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">for</span> i in <span class="title">range</span><span class="params">(len(arrs)</span>):</span></span><br><span class="line"><span class="function">    arrs[i] </span>= <span class="keyword">float</span>(arrs[i] [<span class="number">0</span>:-<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">bin = [<span class="number">0</span>,<span class="number">45</span>,<span class="number">50</span>,<span class="number">55</span>,<span class="number">100</span>]</span><br><span class="line">sel = pd.cut(arrs,bin)</span><br><span class="line"></span><br><span class="line">#pandas的value_counts()函数可以对series里面的每个值进行计数并且排序</span><br><span class="line">pd.value_counts(sel)</span><br><span class="line"></span><br><span class="line">labels = <span class="string">'&lt;= 45kg'</span>,<span class="string">'45~50kg'</span>,<span class="string">'50~55kg'</span>,<span class="string">'&gt;55kg'</span></span><br><span class="line">sizes = pd.value_counts(sel)</span><br><span class="line">explode = (<span class="number">0.1</span>,<span class="number">0.1</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">fig1,ax1 = plt.subplots()</span><br><span class="line">ax1.pie(sizes,explode = explode, labels = labels, autopct = <span class="string">'%1.1f%%'</span>,shadow = True,startangle = <span class="number">90</span>)</span><br><span class="line">ax1.axis(<span class="string">'equal'</span>)</span><br><span class="line">plt.legend(loc = <span class="string">"best"</span>)</span><br><span class="line">plt.title(<span class="string">''</span><span class="string">'《青春有你2》参赛选手'</span><span class="string">''</span>,fontsize = <span class="number">24</span>)</span><br><span class="line">plt.savefig(<span class="string">'/home/aistudio/work/result/pie_result.jpg'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/2020/05/03/%E9%9D%92%E6%98%A5%E6%9C%89%E4%BD%A0%E5%8F%AF%E8%A7%86%E5%8C%96/image-20200503230719831.png" alt="image-20200503230719831"></p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>python 可视化</tag>
      </tags>
  </entry>
  <entry>
    <title>青春有你信息爬取</title>
    <url>/2020/05/03/%E9%9D%92%E6%98%A5%E6%9C%89%E4%BD%A0%E4%BF%A1%E6%81%AF%E7%88%AC%E5%8F%96/</url>
    <content><![CDATA[<p><strong>写在前面</strong></p>
<p>本篇是在百度飞桨学习的第二天的知识点，觉得很有用，所以记录一下。任务是爬取百度百科中青春有你2所有参赛选手的信息</p>
<p><strong>深度学习的一般过程：</strong></p>
<p><img src="/2020/05/03/%E9%9D%92%E6%98%A5%E6%9C%89%E4%BD%A0%E4%BF%A1%E6%81%AF%E7%88%AC%E5%8F%96/image-20200503171342778.png" alt="image-20200503171342778"></p>
<p><strong>收集数据，尤其是有标签，高质量的数据是一件昂贵的工作</strong></p>
<p><strong>爬虫</strong> 的过程，就是模仿浏览器的行为，往目标站点发送请求，接收服务器的响应数据，提取需要的信息，并进行保存的过程。</p>
<p><strong>上网的全过程</strong></p>
<table>
<thead>
<tr>
<th>普通用户：</th>
<th>爬虫的程序</th>
</tr>
</thead>
<tbody><tr>
<td>打开浏览器—-&gt;往目标站点发送请求—–&gt;接受响应数据—–&gt;渲染到页面上</td>
<td>模拟浏览器 –&gt; 往目标站点发送请求 –&gt; 接收响应数据 –&gt; 提取有用的数据 –&gt; 保存到本地/数据库。</td>
</tr>
</tbody></table>
<p><strong>爬虫的过程</strong></p>
<ol>
<li><p>发送请求（request模块）</p>
</li>
<li><p>获取响应的数据（服务器返回）</p>
</li>
<li><p>解析并提取数据（BeautifulSoup查找或者re正则）</p>
</li>
<li><p>保存数据</p>
<p>BeautifulSoup 是一个可以从HTML或XML文件中提取数据的Python库。网址：<a href="https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/" target="_blank" rel="noopener">https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/</a> BeautifulSoup支持Python标准库中的HTML解析器,还支持一些第三方的解析器,其中一个是 lxml。 BeautifulSoup(markup, “html.parser”)或者BeautifulSoup(markup, “lxml”)，推荐使用lxml作为解析器,因为效率更高。</p>
<p><strong>开始前先安装lxml和beautifulSoup</strong></p>
</li>
</ol>
<h1 id="一-爬取青春有你2中所有参赛选手的信息，返回页面数据"><a href="#一-爬取青春有你2中所有参赛选手的信息，返回页面数据" class="headerlink" title="一.爬取青春有你2中所有参赛选手的信息，返回页面数据"></a>一.爬取青春有你2中所有参赛选手的信息，返回页面数据</h1>   <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line">from bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">#获取当天的日期,并进行格式化,用于后面文件命名，格式:20200420</span><br><span class="line">today = datetime.date.today().strftime(<span class="string">'%Y%m%d'</span>)    </span><br><span class="line"></span><br><span class="line"><span class="function">def <span class="title">crawl_wiki_data</span><span class="params">()</span>:</span></span><br><span class="line"><span class="function">    """</span></span><br><span class="line"><span class="function">    爬取百度百科中《青春有你2》中参赛选手信息，返回html</span></span><br><span class="line"><span class="function">    """</span></span><br><span class="line"><span class="function">    headers </span>= &#123; </span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'</span></span><br><span class="line">    &#125;</span><br><span class="line">    url=<span class="string">'https://baike.baidu.com/item/青春有你第二季'</span>                         </span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url,headers=headers)</span><br><span class="line">        print(response.status_code)</span><br><span class="line"></span><br><span class="line">        #将一段文档传入BeautifulSoup的构造方法,就能得到一个文档的对象, 可以传入一段字符串</span><br><span class="line">        soup = BeautifulSoup(response.text,<span class="string">'lxml'</span>)</span><br><span class="line">        </span><br><span class="line">        #返回的是class为table-view log-set-param的&lt;table&gt;所有标签</span><br><span class="line">        tables = soup.find_all(<span class="string">'table'</span>,&#123;<span class="string">'class'</span>:<span class="string">'table-view log-set-param'</span>&#125;)</span><br><span class="line"></span><br><span class="line">        crawl_table_title = <span class="string">"参赛学员"</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> table in  tables:           </span><br><span class="line">            #对当前节点前面的标签和字符串进行查找</span><br><span class="line">            table_titles = table.find_previous(<span class="string">'div'</span>).find_all(<span class="string">'h3'</span>)</span><br><span class="line">            <span class="keyword">for</span> title in table_titles:</span><br><span class="line">                <span class="keyword">if</span>(crawl_table_title in title):</span><br><span class="line">                    <span class="keyword">return</span> table       </span><br><span class="line">    except Exception as e:</span><br><span class="line">        print(e)</span><br></pre></td></tr></table></figure>

<h1 id="二-对爬取的页面数据进行解析，并保存为json文件"><a href="#二-对爬取的页面数据进行解析，并保存为json文件" class="headerlink" title="二.对爬取的页面数据进行解析，并保存为json文件"></a>二.对爬取的页面数据进行解析，并保存为json文件</h1>   <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">def <span class="title">parse_wiki_data</span><span class="params">(table_html)</span>:</span></span><br><span class="line"><span class="function">    '''</span></span><br><span class="line"><span class="function">    从百度百科返回的html中解析得到选手信息，以当前日期作为文件名，存JSON文件,保存到work目录下</span></span><br><span class="line"><span class="function">    '''</span></span><br><span class="line"><span class="function">    bs </span>= BeautifulSoup(str(table_html),<span class="string">'lxml'</span>)</span><br><span class="line">    all_trs = bs.find_all(<span class="string">'tr'</span>)</span><br><span class="line"></span><br><span class="line">    error_list = [<span class="string">'\''</span>,<span class="string">'\"'</span>]</span><br><span class="line"></span><br><span class="line">    stars = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> tr in all_trs[<span class="number">1</span>:]:</span><br><span class="line">         all_tds = tr.find_all(<span class="string">'td'</span>)</span><br><span class="line"></span><br><span class="line">         star = &#123;&#125;</span><br><span class="line"></span><br><span class="line">         #姓名</span><br><span class="line">         star[<span class="string">"name"</span>]=all_tds[<span class="number">0</span>].text</span><br><span class="line">         #个人百度百科链接</span><br><span class="line">         star[<span class="string">"link"</span>]= <span class="string">'https://baike.baidu.com'</span> + all_tds[<span class="number">0</span>].find(<span class="string">'a'</span>).get(<span class="string">'href'</span>)</span><br><span class="line">         #籍贯</span><br><span class="line">         star[<span class="string">"zone"</span>]=all_tds[<span class="number">1</span>].text</span><br><span class="line">         #星座</span><br><span class="line">         star[<span class="string">"constellation"</span>]=all_tds[<span class="number">2</span>].text</span><br><span class="line">         #身高</span><br><span class="line">         star[<span class="string">"height"</span>]=all_tds[<span class="number">3</span>].text</span><br><span class="line">         #体重</span><br><span class="line">         star[<span class="string">"weight"</span>]= all_tds[<span class="number">4</span>].text</span><br><span class="line"></span><br><span class="line">         #花语,去除掉花语中的单引号或双引号</span><br><span class="line">         flower_word = all_tds[<span class="number">5</span>].text</span><br><span class="line">         <span class="keyword">for</span> c in flower_word:</span><br><span class="line">             <span class="keyword">if</span>  c in error_list:</span><br><span class="line">                 flower_word=flower_word.replace(c,<span class="string">''</span>)</span><br><span class="line">         star[<span class="string">"flower_word"</span>]=flower_word </span><br><span class="line">         </span><br><span class="line">         #公司</span><br><span class="line">         <span class="keyword">if</span> not all_tds[<span class="number">6</span>].find(<span class="string">'a'</span>) is  None:</span><br><span class="line">             star[<span class="string">"company"</span>]= all_tds[<span class="number">6</span>].find(<span class="string">'a'</span>).text</span><br><span class="line">         <span class="keyword">else</span>:</span><br><span class="line">             star[<span class="string">"company"</span>]= all_tds[<span class="number">6</span>].text  </span><br><span class="line"></span><br><span class="line">         stars.append(star)</span><br><span class="line"></span><br><span class="line">    json_data = json.loads(str(stars).replace(<span class="string">"\'"</span>,<span class="string">"\""</span>))   </span><br><span class="line">    <span class="function">with <span class="title">open</span><span class="params">(<span class="string">'work/'</span> + today + <span class="string">'.json'</span>, <span class="string">'w'</span>, encoding=<span class="string">'UTF-8'</span>)</span> as f:</span></span><br><span class="line"><span class="function">        json.<span class="title">dump</span><span class="params">(json_data, f, ensure_ascii=False)</span></span></span><br></pre></td></tr></table></figure>

<p>   <strong>三. 爬取每个选手的百度百科图片，并进行保存</strong></p>
<h1 id="三-爬取每个选手的百度百科图片，并进行保存"><a href="#三-爬取每个选手的百度百科图片，并进行保存" class="headerlink" title="三. 爬取每个选手的百度百科图片，并进行保存"></a>三. 爬取每个选手的百度百科图片，并进行保存</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">def <span class="title">crawl_pic_urls</span><span class="params">()</span>:</span></span><br><span class="line"><span class="function">    '''</span></span><br><span class="line"><span class="function">    爬取每个选手的百度百科图片，并保存</span></span><br><span class="line"><span class="function">    ''' </span></span><br><span class="line"><span class="function">    with <span class="title">open</span><span class="params">(<span class="string">'work/'</span>+ today + <span class="string">'.json'</span>, <span class="string">'r'</span>, encoding=<span class="string">'UTF-8'</span>)</span> as file:</span></span><br><span class="line"><span class="function">         json_array </span>= json.loads(file.read())</span><br><span class="line"></span><br><span class="line">    headers = &#123; </span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'</span> </span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> star in json_array:</span><br><span class="line"></span><br><span class="line">        name = star[<span class="string">'name'</span>]</span><br><span class="line">        link = star[<span class="string">'link'</span>]</span><br><span class="line"></span><br><span class="line">        #向选手的个人百科发送一个http get 请求   </span><br><span class="line">        response = requests.get(link,headers = headers)</span><br><span class="line"></span><br><span class="line">        #获取文档对象</span><br><span class="line">        bs = BeautifulSoup(response.text,<span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line">        #从选手百科页面中解析链接，该链接指向选手图片列表页面</span><br><span class="line">        pic_list_url = bs.select(<span class="string">'.summary-pic a'</span>)[<span class="number">0</span>].get(<span class="string">'href'</span>)</span><br><span class="line">        pic_list_urls = <span class="string">'https://baike.baidu.com'</span> + pic_list_url</span><br><span class="line"></span><br><span class="line">        #获取选手的http</span><br><span class="line">        pic_list_response = requests.get(pic_list_urls,headers = headers)</span><br><span class="line"></span><br><span class="line">        #对选手图片列表进行解析，获取所有图片链接</span><br><span class="line">        bs = BeautifulSoup(pic_list_response.text,<span class="string">'lxml'</span>)</span><br><span class="line">        pic_list_html = bs.select(<span class="string">'.pic-list img '</span>)</span><br><span class="line"></span><br><span class="line">        #定义图片链接存放列表</span><br><span class="line">        pic_urls = []</span><br><span class="line"></span><br><span class="line">        #获取对应的图片链接并保存在pic_urls中</span><br><span class="line">        <span class="keyword">for</span> pic_html in pic_list_html:</span><br><span class="line">            pic_url = pic_html.get(<span class="string">'src'</span>)</span><br><span class="line">            pic_urls.append(pic_url)</span><br><span class="line">            </span><br><span class="line">        #！！！根据图片链接列表pic_urls, 下载所有图片，保存在以name命名的文件夹中！！！</span><br><span class="line">        down_pic(name,pic_urls)</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">def <span class="title">down_pic</span><span class="params">(name,pic_urls)</span>:</span></span><br><span class="line"><span class="function">    '''</span></span><br><span class="line"><span class="function">    根据图片链接列表pic_urls, 下载所有图片，保存在以name命名的文件夹中,</span></span><br><span class="line"><span class="function">    '''</span></span><br><span class="line"><span class="function">    path </span>= <span class="string">'work/'</span>+<span class="string">'pics/'</span>+name+<span class="string">'/'</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> not os.path.exists(path):</span><br><span class="line">      os.makedirs(path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, <span class="function">pic_url in <span class="title">enumerate</span><span class="params">(pic_urls)</span>:</span></span><br><span class="line"><span class="function">        <span class="keyword">try</span>:</span></span><br><span class="line"><span class="function">            pic </span>= requests.get(pic_url, timeout=<span class="number">15</span>)</span><br><span class="line">            string = str(i + <span class="number">1</span>) + <span class="string">'.jpg'</span></span><br><span class="line">            <span class="function">with <span class="title">open</span><span class="params">(path+string, <span class="string">'wb'</span>)</span> as f:</span></span><br><span class="line"><span class="function">                f.<span class="title">write</span><span class="params">(pic.content)</span></span></span><br><span class="line"><span class="function">                <span class="title">print</span><span class="params">(<span class="string">'成功下载第%s张图片: %s'</span> % (str(i + <span class="number">1</span>)</span>, <span class="title">str</span><span class="params">(pic_url)</span>))</span></span><br><span class="line"><span class="function">        except Exception as e:</span></span><br><span class="line"><span class="function">            <span class="title">print</span><span class="params">(<span class="string">'下载第%s张图片时失败: %s'</span> % (str(i + <span class="number">1</span>)</span>, <span class="title">str</span><span class="params">(pic_url)</span>))</span></span><br><span class="line"><span class="function">            <span class="title">print</span><span class="params">(e)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">continue</span></span></span><br></pre></td></tr></table></figure>

<h1 id="四-打印爬取的所有图片的路径"><a href="#四-打印爬取的所有图片的路径" class="headerlink" title="四.打印爬取的所有图片的路径"></a>四.打印爬取的所有图片的路径</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">def <span class="title">show_pic_path</span><span class="params">(path)</span>:</span></span><br><span class="line"><span class="function">    '''</span></span><br><span class="line"><span class="function">    遍历所爬取的每张图片，并打印所有图片的绝对路径</span></span><br><span class="line"><span class="function">    '''</span></span><br><span class="line"><span class="function">    pic_num </span>= <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> (dirpath,dirnames,filenames) in os.walk(path):</span><br><span class="line">        <span class="keyword">for</span> filename in filenames:</span><br><span class="line">           pic_num += <span class="number">1</span></span><br><span class="line">           print(<span class="string">"第%d张照片：%s"</span> % (pic_num,os.path.join(dirpath,filename)))           </span><br><span class="line">    print(<span class="string">"共爬取《青春有你2》选手的%d照片"</span> % pic_num)</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">     #爬取百度百科中《青春有你2》中参赛选手信息，返回html</span><br><span class="line">     html = crawl_wiki_data()</span><br><span class="line"></span><br><span class="line">     #解析html,得到选手信息，保存为json文件</span><br><span class="line">     parse_wiki_data(html)</span><br><span class="line"></span><br><span class="line">     #从每个选手的百度百科页面上爬取图片,并保存</span><br><span class="line">     crawl_pic_urls()</span><br><span class="line"></span><br><span class="line">     #打印所爬取的选手图片路径</span><br><span class="line">     show_pic_path(<span class="string">'/home/aistudio/work/pics/'</span>)</span><br><span class="line"></span><br><span class="line">     print(<span class="string">"所有信息爬取完成！"</span>)</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>Python</tag>
      </tags>
  </entry>
</search>
